{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "from src.nn.saint import SAINTClassifier\n",
    "# export mnist\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_set = datasets.MNIST(\n",
    "    root='data', \n",
    "    train=True, \n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda x: x.view(-1)),\n",
    "        transforms.Lambda(lambda x: (x > 0.1).long())\n",
    "    ])\n",
    ")\n",
    "# split data into train and validation\n",
    "train_set, val_set = torch.utils.data.random_split(train_set, [50000, 10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "def train_model_epoch(\n",
    "    model,\n",
    "    data_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    verbose: int=-1\n",
    "):\n",
    "    loss_accum = 0.0\n",
    "    model.train()\n",
    "    for step, (x, y) in enumerate(data_loader):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model((None, x), y)\n",
    "        loss = output.loss\n",
    "        \n",
    "        optimizer.step()\n",
    "        loss_accum += loss.detach()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if verbose > 0 and (step + 1) % verbose == 0:\n",
    "            loss_mean = loss_accum / (step + 1)\n",
    "            print(f'step: {step + 1:4d}, loss: {loss_mean:.4f}')\n",
    "\n",
    "    return model, loss_accum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, device):\n",
    "    loss_accm = 0.0\n",
    "    n_correct, n_total = 0, 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in data_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            output = model((None, x), y)\n",
    "            loss = output.loss\n",
    "            loss_accm += loss.detach() * x.size(0)\n",
    "\n",
    "            pred = output.logits.argmax(dim=-1)\n",
    "            n_correct += (pred == y).sum().item()\n",
    "            n_total += y.size(0)\n",
    "    loss = loss_accm / n_total\n",
    "    acc = n_correct / n_total\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    n_epochs: int=10,\n",
    "):\n",
    "    for epoch in range(n_epochs):\n",
    "        model, train_loss = train_model_epoch(model, train_loader, optimizer, device, verbose=-1)\n",
    "        train_loss /= len(train_loader)\n",
    "        # evaluate on validation set\n",
    "        train_loss, train_acc = evaluate(model, train_loader, device)\n",
    "        valid_loss, valid_acc = evaluate(model, valid_loader, device)\n",
    "        print(f'epoch: {epoch + 1:3d}, train_loss: {train_loss:.4f}, train_acc: {train_acc:.4f}, valid_loss: {valid_loss:.4f}, valid_acc: {valid_acc:.4f}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAINTClassifier(\n",
    "    dense_size=0,\n",
    "    sparse_size=784,\n",
    "    sparse_key_size=2,\n",
    "    num_hiddens=32,\n",
    "    num_classes=10,\n",
    "    num_layers=4,\n",
    "    num_heads=4,\n",
    "    inter_sample=False,\n",
    "    col_attn_latent_dim=32,\n",
    "    row_attn_latent_dim=64,\n",
    "    attn_dropout=0.2,\n",
    "    ffn_dropout=0.2,\n",
    "    ffn_hiddens_factor=4,\n",
    "    col_embedding=True\n",
    ")\n",
    "optimizer = model.build_optimizer(lr=1e-4, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data loader\n",
    "train_loader = DataLoader(train_set, batch_size=128, shuffle=True)\n",
    "valid_loader = DataLoader(val_set, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1, train_loss: 0.1541, train_acc: 0.9506, valid_loss: 0.1663, valid_acc: 0.9454\n",
      "epoch:   2, train_loss: 0.1575, train_acc: 0.9490, valid_loss: 0.1728, valid_acc: 0.9458\n",
      "epoch:   3, train_loss: 0.1531, train_acc: 0.9505, valid_loss: 0.1663, valid_acc: 0.9467\n",
      "epoch:   4, train_loss: 0.1483, train_acc: 0.9527, valid_loss: 0.1607, valid_acc: 0.9485\n",
      "epoch:   5, train_loss: 0.1534, train_acc: 0.9511, valid_loss: 0.1687, valid_acc: 0.9462\n",
      "epoch:   6, train_loss: 0.1488, train_acc: 0.9525, valid_loss: 0.1650, valid_acc: 0.9480\n",
      "epoch:   7, train_loss: 0.1484, train_acc: 0.9527, valid_loss: 0.1621, valid_acc: 0.9481\n",
      "epoch:   8, train_loss: 0.1503, train_acc: 0.9509, valid_loss: 0.1672, valid_acc: 0.9469\n",
      "epoch:   9, train_loss: 0.1413, train_acc: 0.9544, valid_loss: 0.1549, valid_acc: 0.9514\n",
      "epoch:  10, train_loss: 0.1434, train_acc: 0.9541, valid_loss: 0.1561, valid_acc: 0.9508\n",
      "epoch:  11, train_loss: 0.1453, train_acc: 0.9534, valid_loss: 0.1610, valid_acc: 0.9486\n",
      "epoch:  12, train_loss: 0.1390, train_acc: 0.9552, valid_loss: 0.1525, valid_acc: 0.9505\n",
      "epoch:  13, train_loss: 0.1375, train_acc: 0.9555, valid_loss: 0.1523, valid_acc: 0.9521\n",
      "epoch:  14, train_loss: 0.1341, train_acc: 0.9570, valid_loss: 0.1468, valid_acc: 0.9533\n",
      "epoch:  15, train_loss: 0.1302, train_acc: 0.9584, valid_loss: 0.1440, valid_acc: 0.9542\n",
      "epoch:  16, train_loss: 0.1309, train_acc: 0.9578, valid_loss: 0.1439, valid_acc: 0.9543\n",
      "epoch:  17, train_loss: 0.1319, train_acc: 0.9582, valid_loss: 0.1459, valid_acc: 0.9545\n",
      "epoch:  18, train_loss: 0.1277, train_acc: 0.9592, valid_loss: 0.1436, valid_acc: 0.9552\n",
      "epoch:  19, train_loss: 0.1262, train_acc: 0.9594, valid_loss: 0.1392, valid_acc: 0.9566\n",
      "epoch:  20, train_loss: 0.1218, train_acc: 0.9616, valid_loss: 0.1370, valid_acc: 0.9579\n",
      "epoch:  21, train_loss: 0.1202, train_acc: 0.9622, valid_loss: 0.1367, valid_acc: 0.9576\n",
      "epoch:  22, train_loss: 0.1166, train_acc: 0.9632, valid_loss: 0.1310, valid_acc: 0.9586\n",
      "epoch:  23, train_loss: 0.1179, train_acc: 0.9623, valid_loss: 0.1354, valid_acc: 0.9573\n",
      "epoch:  24, train_loss: 0.1139, train_acc: 0.9641, valid_loss: 0.1319, valid_acc: 0.9586\n",
      "epoch:  25, train_loss: 0.1146, train_acc: 0.9636, valid_loss: 0.1326, valid_acc: 0.9580\n",
      "epoch:  26, train_loss: 0.1102, train_acc: 0.9648, valid_loss: 0.1279, valid_acc: 0.9601\n",
      "epoch:  27, train_loss: 0.1111, train_acc: 0.9649, valid_loss: 0.1286, valid_acc: 0.9600\n",
      "epoch:  28, train_loss: 0.1098, train_acc: 0.9652, valid_loss: 0.1312, valid_acc: 0.9588\n",
      "epoch:  29, train_loss: 0.1042, train_acc: 0.9667, valid_loss: 0.1224, valid_acc: 0.9627\n",
      "epoch:  30, train_loss: 0.1058, train_acc: 0.9669, valid_loss: 0.1242, valid_acc: 0.9611\n",
      "epoch:  31, train_loss: 0.1049, train_acc: 0.9666, valid_loss: 0.1258, valid_acc: 0.9604\n",
      "epoch:  32, train_loss: 0.1010, train_acc: 0.9678, valid_loss: 0.1230, valid_acc: 0.9610\n",
      "epoch:  33, train_loss: 0.0993, train_acc: 0.9684, valid_loss: 0.1196, valid_acc: 0.9633\n",
      "epoch:  34, train_loss: 0.0980, train_acc: 0.9692, valid_loss: 0.1174, valid_acc: 0.9626\n",
      "epoch:  35, train_loss: 0.0970, train_acc: 0.9696, valid_loss: 0.1178, valid_acc: 0.9638\n",
      "epoch:  36, train_loss: 0.0953, train_acc: 0.9696, valid_loss: 0.1173, valid_acc: 0.9634\n",
      "epoch:  37, train_loss: 0.0934, train_acc: 0.9706, valid_loss: 0.1165, valid_acc: 0.9637\n",
      "epoch:  38, train_loss: 0.0893, train_acc: 0.9714, valid_loss: 0.1133, valid_acc: 0.9638\n",
      "epoch:  39, train_loss: 0.0922, train_acc: 0.9703, valid_loss: 0.1179, valid_acc: 0.9643\n",
      "epoch:  40, train_loss: 0.0856, train_acc: 0.9731, valid_loss: 0.1111, valid_acc: 0.9647\n",
      "epoch:  41, train_loss: 0.0844, train_acc: 0.9732, valid_loss: 0.1107, valid_acc: 0.9663\n",
      "epoch:  42, train_loss: 0.0872, train_acc: 0.9724, valid_loss: 0.1151, valid_acc: 0.9630\n",
      "epoch:  43, train_loss: 0.0850, train_acc: 0.9733, valid_loss: 0.1151, valid_acc: 0.9631\n",
      "epoch:  44, train_loss: 0.0861, train_acc: 0.9727, valid_loss: 0.1129, valid_acc: 0.9632\n",
      "epoch:  45, train_loss: 0.0777, train_acc: 0.9756, valid_loss: 0.1074, valid_acc: 0.9666\n",
      "epoch:  46, train_loss: 0.0752, train_acc: 0.9768, valid_loss: 0.1075, valid_acc: 0.9662\n",
      "epoch:  47, train_loss: 0.0761, train_acc: 0.9772, valid_loss: 0.1079, valid_acc: 0.9670\n",
      "epoch:  48, train_loss: 0.0733, train_acc: 0.9771, valid_loss: 0.1061, valid_acc: 0.9679\n",
      "epoch:  49, train_loss: 0.0739, train_acc: 0.9774, valid_loss: 0.1069, valid_acc: 0.9673\n",
      "epoch:  50, train_loss: 0.0680, train_acc: 0.9786, valid_loss: 0.0997, valid_acc: 0.9686\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, train_loader, valid_loader, optimizer, device, n_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
